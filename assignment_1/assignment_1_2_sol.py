# -*- coding: utf-8 -*-
"""Assignment_1_2_sol.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vlQaZ8r8j7tEcZvKBaXW3TgV7--RwemY

#Francis Ndikum Nji

#Campus ID: RN49536

Solution to Question 2
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
!pip install graphviz
!apt install libgraphviz-dev
!pip install pygraphviz
!pip install zepid
from zepid.causal.causalgraph import DirectedAcyclicGraph

import networkx as nx
from networkx.drawing.nx_agraph import graphviz_layout, to_agraph
import pygraphviz as pgv

import seaborn as sns
!pip install causalgraphicalmodels
from causalgraphicalmodels import CausalGraphicalModel
from causalgraphicalmodels.examples import fork, chain, collider

"""---
#1. The causal graph with Zepid library
---
I used this library to have the same graph structure
"""

from zepid.causal.causalgraph import DirectedAcyclicGraph
dag = DirectedAcyclicGraph(exposure='X', outcome="Y")
dag.add_arrows((('X', 'W'), ('W', 'Y'),
                ('B', 'A'), ('B', 'Z'),
                ('C', 'D'), ('C', 'Z'),
                ('Z', 'X'), ('Z', 'Y'),
                ('A', 'X'), ('D', 'Y')
                ))
pos = {"X": [0, 0], "W": [1, 0], "Y": [2, 0],"Z": [1, 1],
       "A": [0, 1], "B": [0, 2],"D": [2, 1], "C": [2, 2]}

dag.draw_dag(positions=pos)
plt.tight_layout()
plt.show()

"""###Using the causalgraphicalmodels library"""

from causalgraphicalmodels import CausalGraphicalModel

sprinkler = CausalGraphicalModel(
    nodes={"X": [0, 0], "W": [1, 0], "Y": [2, 0],"Z": [1, 1],
       "A": [0, 1], "B": [0, 2],"D": [2, 1], "C": [2, 2]},
    edges=[
        ('X', 'W'), ('W', 'Y'),
                ('B', 'A'), ('B', 'Z'),
                ('C', 'D'), ('C', 'Z'),
                ('Z', 'X'), ('Z', 'Y'),
                ('A', 'X'), ('D', 'Y')

    ]
)

# draw return a graphviz `dot` object, which jupyter can render
# sprinkler.draw()

"""---
#2.   Write code to find all backdoor paths from X to Y.
---
"""

#To get all backdoor paths from X to Y.
sprinkler.get_all_backdoor_paths("X", "Y")

"""But because Z acts as a collider in the path  {X, A, B, Z, C, D, Y}, it is blocked unless conditioned on. To find a valid adjustment set, we need a set which blocks this path. The function "is_valid_backdoor_adjustment_set" tests the validity of the adjustment set and outputs "True" for a valid set or "False" for an invalid set."""

sprinkler.is_valid_backdoor_adjustment_set("X", "Y", {'Z'})

sprinkler.is_valid_backdoor_adjustment_set("X", "Y", {'Z', 'C', 'D'})

sprinkler.is_valid_backdoor_adjustment_set("X", "Y", {'A', 'B', 'Z'})

sprinkler.is_valid_backdoor_adjustment_set("X", "Y", {'A', 'B', 'Z', 'C', 'D'})

sprinkler.is_valid_backdoor_adjustment_set("X", "Y", {'B', 'Z', 'C'})



"""---
#3.   List all of the sets of variables that satisfy the backdoor criterion.
---
"""

#Possible adjustment set

dag.calculate_adjustment_sets()
print(dag.adjustment_sets)

#To compute all valid adjustment sets 
sprinkler.get_all_backdoor_adjustment_sets("X", "Y")



"""#4. Minimal sets of variables that satisfy the backdoor criterion to determine the causal effect of X on Y.

From the causal graph above, we see that the node Z is present in all four backdoor paths from X to Y, and Z is a collider on the path [X, A, B, Z, C, D, Y]. Conditioning on Z will unblock this path and will violate the
backdoor criterion. To block all backdoor paths, we must also condition on one of its parents (or their descendants), giving us a choice of one of (A, B, C, or D). Z in addition to any combinations of these 4 nodes will fulfill the back-door criteria. So we could adjust on (Z, A), (Z, B), (Z, C), (Z, D). We see, therefore, that Z, a collider, must be adjusted for in any set that yields an unbiased estimate of the effect of X on Y.

#5. Write code to load and take a look at the data.
"""

#path = /content/drive/MyDrive/Fall_2022/IS_800_Causality_New/Assignment_1/DatasetProblem2.csv
data = pd.read_csv('/content/drive/MyDrive/Fall_2022/IS_800_Causality_New/Assignment_1/DatasetProblem2.csv')
data.head()

data.describe()

data.info()

data.isnull().sum()

"""#6. write code to find the causal effect of X on Y for the following adjustment sets:
a. Empty adjustment set, {}
b. {Z}
c. {Z, A}
d. {Z, B}
e. {Z, C}
f. {Z, D}
g. {A, B, C, D}
h. {Z, A, B, C, D}
"""

# An approach to causal effect estimation - no bootstrapping
def causalEffectEstimation(data, xColumns, xColumnsLabel, zColumns, yColumns, model = RandomForestClassifier(n_estimators=10)):
    # separate data into treatment, adjustment set, outcome
    # treatment, X
    trainX = data[xColumns]
    # adjustment set, Z
    trainZ = data[zColumns]
    # outcome, Y
    trainY = data[yColumns]
    
    # merge treatment, X and adjustment, Z
    trainXZ = pd.concat([trainX, trainZ], axis = 1)

    # we fit a ML model 
    model.fit(trainXZ, trainY)

    ## Causal effect estimation 

    # No treatment: Set X = 0.
    testXZPlacebo = trainXZ.copy()
    testXZPlacebo[xColumns] = 0
    # With treatment: Set X = 1.
    testXZTreatment = trainXZ.copy()
    testXZTreatment[xColumns] = 1

    # Estimate outcome without treatment    
    placeboEstimate = np.mean(model.predict(testXZPlacebo))
    # Estimate outcome without treatment   
    treatmentEstimate = np.mean(model.predict(testXZTreatment))
    
    # Estimate average treatment effect
    causalEffect = treatmentEstimate - placeboEstimate

    # Print results:    
    # print('Placebo estimate:' + str(placeboEstimate))
    # print('Treatment estimate:' + str(treatmentEstimate))
    print('Causal effect:' + str(causalEffect))

# Adjust Nothing
xColumns = ['X']
zColumns = []
yColumns = ['Y']
causalEffectEstimation(data, xColumns, 'X', zColumns, yColumns, LinearRegression())

# Adjust Z
xColumns = ['X']
zColumns = ['Z']
yColumns = ['Y']
causalEffectEstimation(data, xColumns, 'X', zColumns, yColumns, LinearRegression())

# Adjust Z and A
xColumns = ['X']
zColumns = ['A', 'Z']
yColumns = ['Y']
causalEffectEstimation(data, xColumns, 'X', zColumns, yColumns, LinearRegression())

# Adjust Z and B
xColumns = ['X']
zColumns = ['B','Z']
yColumns = ['Y']
causalEffectEstimation(data, xColumns, 'X', zColumns, yColumns, LinearRegression())

# Adjust Z and C
xColumns = ['X']
zColumns = ['C', 'Z']
yColumns = ['Y']
causalEffectEstimation(data, xColumns, 'X', zColumns, yColumns, LinearRegression())

# Adjust Z and D
xColumns = ['X']
zColumns = ['D', 'Z']
yColumns = ['Y']
causalEffectEstimation(data, xColumns, 'X', zColumns, yColumns, LinearRegression())

# Adjust A, B, C, D
xColumns = ['X']
zColumns = ['A', 'B', 'C', 'D']
yColumns = ['Y']
causalEffectEstimation(data, xColumns, 'X', zColumns, yColumns, LinearRegression())

# Adjust A, B, C, D
xColumns = ['X']
zColumns = ['Z', 'A', 'B', 'C', 'D']
yColumns = ['Y']
causalEffectEstimation(data, xColumns, 'X', zColumns, yColumns, LinearRegression())

"""#7. Explain the similarities and differences in results that found in question 6(a)-(h) based on different adjustment sets. Hint: you can use your answer to question 2, 3 and 4 to explain it.

Adjustment Formula in Potential Outcomes Framework is based on the untestable conditional exchangeability or unconfoundness assumption. Our goal is to look for that variable that when conditioned on meets the conditional exchangeability assumption.

*  First we need to identify all confounding variables which are Z, B and C so conditioning on these confounding variables meets the conditional exchangeability assumption more than on other variables
*   Z is a collider in the path [X, Z, Y] and a confounder in the path [X, A, B, Z, C, D, Y]

*   From our causal effect estimation, we see that adjustments on [B, Z] and [C, Z] yield very similar results or causal estimates.
*   In (a) we have the highest efect which implies that no adjustment is necessary to estimate the causal effect of X on Y. This could also be observed that adjusting on [A, B, C, D] without Z yields a higher estimate than an adjustment set with Z.



"""